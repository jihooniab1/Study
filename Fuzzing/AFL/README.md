# AFL 분석
LKL을 활용한 파일 시스템 개발 과정에서 Janus와 기본 AFL의 **afl-fuzz.c** 파일을 분석, 비교해보고자 한다.

# 목차
- [1. American Fuzzy Lop](#american-fuzzy-lop-공부하기)
    - [1.1 technical detail](#technical-detail)

# American Fuzzy Lop 공부하기
## Technical Detail
### 1. 커버리지 측정
컴파일된 프로그램에 삽입된 **계측(instrumentation)** 은 대략적인 분기 실행 횟수와 함께 `분기(branch), edge` 커버리지를 캡처합니다. 분기 지점에 주입된 코드는 본질적으로 다음과 같습니다.
```
cur_location = <컴파일 타임 랜덤값>;
shared_mem[cur_location ^ prev_location]++;
prev_location = cur_location >> 1;
```
**cur_location** 값은 복잡한 프로젝트의 링킹 과정을 단순화하고 XOR 출력이 균등하게 분산되도록 하기 위해 무작위로 생성됩니다. 

**shared_mem[]** 배열은 호출자가 계측된 바이너리에 전달하는 **64KB 공유 메모리(SHM) 영역** 입니다. 출력 맵에서 설정된 모든 바이트는 계측된 코드에서 특정 **(branch_src, branch_dst)(분기 소스, 분기 목적지)** 튜플에 대한 히트로 간주할 수 있습니다. 

맵의 크기는 거의 모든 대상 타겟에서 충돌이 산발적으로 발생하도록 선택되었습니다. 일반적으로 이러한 타겟들은 2천에서 1만 개의 발견 가능한 분기 지점을 가집니다:

```
    분기 개수  | 충돌하는 튜플    | 예시 타겟
 -----------+---------------+------------------
       1,000 | 0.75%         | giflib, lzo
       2,000 | 1.5%          | zlib, tar, xz
       5,000 | 3.5%          | libpng, libwebp
      10,000 | 7%            | libxml
      20,000 | 14%           | sqlite
      50,000 | 30%           | -

>> 충돌 30퍼센트의 경우도 부정확하지만 여전히 유용함
```

동시에 맵의 크기는 수신하는 측에서 맵을 마이크로초 단위로 분석할 수 있을 만큼 충분히 작고, L2 캐시에 쉽게 맞을 수 있도록 작습니다.이러한 형태의 커버리지는 단순한 블록 커버리지보다 프로그램의 실행 경로에 대해 상당히 더 많은 정보를 제공합니다. 특히 다음과 같은 **실행추적(execution trace)** 을 쉽게 구별할 수 있습니다:
```
 A -> B -> C -> D -> E (튜플: AB, BC, CD, DE)
 A -> B -> D -> C -> E (튜플: AB, BD, DC, CE)

>> 블록 커버리지는 블록의 실행 여부만 판단해서 엣지 커버리지보다 정보가 부족함..
```

이는 기본 코드에서 미묘한 결함 조건을 찾는데 도움이 됩니다. 보안 취약점은 단순히 새로운 기본 블록에 도달하는 것보다는 예상치 못한 또는 잘못된 상태 전환과 더 자주 연관되기 때문입니다.

이 섹션 앞부분에서 보여준 의사코드 마지막 줄의 시프트 연산의 이유는 튜플의 방향성을 보존하고 (이것 없이는 **A^B가 B^A 와 구별이 안 됨**), 타이트 루프의 정체성을 유지하기 위함입니다(그렇지 않으면 A^A가 B^B와 명백히 같아짐).

### 2. 새로운 행동 탐지하기
퍼저는 이전 실행에서 **발견된 튜플들의 전역 맵** 을 유지합니다. 이 데이터는 개별 추적과 빠르게 비교될 수 있고, 단지 몇 개의 dword 또는 qword 크기의 명령어와 간단한 루프로 업데이트될 수 있습니다.

변형된 입력이 새로운 튜플을 포함하는 실행 추적을 생성하면 해당 입력 파일이 보존되고 나중에 추가 처리를 위해 라우팅됩니다. 실행 추적에서 **새로운 지역적 상태 전환** 을 트리거하지 않는 입력들(즉, 새로운 튜플을 생성하지 않는 입력들)은, 전체적인 제어 흐름 시퀀스가 고유하더라도 버려집니다. 

이 접근법은 복잡한 실행 추적의 계산적으로 집약적이고 취약한 전역 비교를 수행하지 않아도, 경로 폭발을 피하면서도 프로그램 상태의 세밀(fine-grained)하고 장기적인 탐색을 가능하게 합니다.

알고리즘의 특성을 설명하기 위해, 아래에 표시된 두 번째 trace는 **새로운 튜플(CA, AE)** 의 존재로 인해 실질적으로 새로운 것으로 간주될 것입니다:
```d
#1: A -> B -> C -> D -> E
#2: A -> B -> C -> A -> E
```

동시에 #2가 처리된 후, 다음 패턴은 현저히 다른 전체 실행 경로를 가짐에도 불구하고 고유한 것으로 보이지 않을 것입니다:
```
#3: A -> B -> C -> A -> B -> C -> A -> B -> C -> D -> E
```

새로운 튜플 감지에 더해, 퍼저는 또한 `대략적인(coarse)` 튜플 히트 카운트를 고려합니다. 이것들은 여러 버킷으로 나뉩니다:
```
1, 2, 3, 4-7, 8-15, 16-31, 32-127, 128+

>> 버킷1은 1번, 버킷2는 2번, ... 버킷 6은 16-31번 느낌
```

어느 정도 버킷의 수는 구현상의 산물로, 계측에 의해 생성된 8비트 카운터를 **8-position 비트맵** 에 in-place 매핑(실행 횟수를 바로 비트맵으로 변환)하는 것을 허용하며, 이는 퍼저 실행 파일이 각 튜플에 대해 이미 본 실행 카운트를 추적하기 위해 의존하는 것입니다. 

```
<8-position bitmap>
비트맵:  00000010
        ||||||||
        |||||||└─ 버킷1 (1번)
        ||||||└── 버킷2 (2번) ← 이 비트가 1
        |||||└─── 버킷3 (3번)  
        ||||└──── 버킷4 (4-7번)
        |||└───── 버킷5 (8-15번)
        ||└────── 버킷6 (16-31번)
        |└─────── 버킷7 (32-127번)
        └──────── 버킷8 (128+번)
```

단일 버킷의 범위 내 변화는 무시됩니다; 한 버킷에서 다른 버킷으로의 전환은 프로그램 제어 흐름에서 **흥미로운 변화** 로 플래그되고, 아래 섹션에서 설명하는 진화 프로세스(evolutionary process)로 라우팅됩니다.

히트 카운트 동작은 잠재적으로 흥미로운 제어 흐름 변화를 구별하는 방법을 제공합니다. 예를 들어 정상적으로 한 번만 히트되던 코드 블록이 두 번 실행되는 경우 등입니다. 동시에 이는 경험적으로 덜 주목할 만한 변화들, 예를 들어 루프가 47 사이클에서 48 사이클로 가는 것 같은 변화에는 둔감합니다. 카운터들은 또한 밀집된 추적 맵에서 튜플 충돌에 대해 어느 정도의 **우연한 면역성** 을 제공합니다.

실행은 메모리와 실행 시간 제한을 통해 엄격하게 제어됩니다. 기본적으로 타임아웃은 **초기 보정(initially-calibrated)된** 실행 속도의 5배로 설정되며, 20ms로 반올림됩니다. 공격적인 타임아웃은 커버리지를 1% 향상시키면서 100배 느린 경로로 빠져버려 퍼저 성능이 극도로 떨어지는 경우 같은 걸 막기 위함입니다; 우리는 실용적인 측면에서 이를 거부하고 퍼저가 같은 코드에 도달하는 덜 비싼 방법을 찾기를 희망합니다. 경험적 테스트는 더 관대한 시간 제한이 비용에 비해 가치가 없음을 강하게 시사합니다.

### 3. 입력 큐 진화시키기
새로운 상태 변화를 만들어낸 변이된 테스트 케이스들은 **입력 큐(input queue)** 에 들어가고, 미래 라운드의 시작점으로 사용됩니다. 이들은 기존 발견들을 보완하되 대체하지는 않습니다. 더 `탐욕적인 genetic algorithm`과 대조적으로, 이 접근법은 퍼저 도구가 기본 데이터 형식의 다양한 특징들을 **점진적으로** 탐색할 수 있게 합니다.

알고리즘을 통해 생성된 **합성 코퍼스(synthetic corpus)** 는 `뭔가 새롭거나 흥미로워 보이는 거`의 집합으로 향후 다른 테스팅 프로세스를 시드하는데 사용될 수 있습니다. 이 접근을 통해 대부분의 타겟에 대해 큐의 크기는 1K에서 10K 사이로 증가하고, 이 중 10-30 퍼센트 정도는 새로운 튜플의 발견, 나머지는 히트 카운트 변화에 영향을 줍니다.

다음 표는 가이드된 퍼징에 대한 여러 다른 접근법을 사용할 때, 파일 syntax를 발견하고 프로그램 상태를 탐색하는 상대적 능력을 비교합니다. 계측된 타겟은 -03로 컴파일된 GNU patch 2.3.7이었고 더미 텍스트 파일로 시드되었습니다. 세션은 `afl-fuzz`로 입력 큐를 한 번 통과한 것으로 구성되었습니다:
```
   퍼저 가이던스  | 도달한  | 도달한  | 엣지 히트   | 최고 커버리지
   전략 사용     | 블록    | 엣지   | 카운트 변화 | 생성된 테스트 케이스
 ----------------+--------+--------+----------+---------------------------
    (초기 파일)  | 156    | 163    | 1.00     | (없음)
               |        |        |          |
  블라인드 퍼징 S | 182    | 205    | 2.23     | RCS diff의 첫 2B
  블라인드 퍼징 L | 228    | 265    | 2.23     | -c 모드 diff의 첫 4B
    블록 커버리지 | 855    | 1,130  | 1.57     | 거의 유효한 RCS diff
    엣지 커버리지 | 1,452  | 2,070  | 2.18     | 한 청크 -c 모드 diff
       AFL 모델 | 1,765  | 2,597  | 4.99     | 네 청크 -c 모드 diff >> 4개 변경사항이 담긴 복잡한 diff 파일을 만들어냈다는 뜻
```

블라인드 퍼징의 **첫 번째 항목("S")** 은 단일 테스팅 라운드 실행에 해당합니다; **두 번째 수치 세트("L"** )는 계측된 실행과 비교 가능한 수의 실행 사이클 동안 루프에서 실행되는 퍼저를 보여주며, 이는 증가하는 큐를 완전히 처리하는 데 더 많은 시간이 필요했습니다.

퍼저가 모든 랜덤 퍼징 단계를 컴파일에서 제외하고 순차적인 비트 플립 워킹과 같은 일련의 기본적이고 순차적인 연산만 남기도록 수정된 별도의 실험에서 대략 유사한 결과가 얻어졌습니다. 이 모드는 입력 파일의 크기를 변경할 수 없기 때문에, 세션들은 **유효한 unified diff** 로 시드되었습니다:

```
   큐 확장        | 도달한 | 도달한  | 엣지 히트  | 발견된 고유
   전략 사용      | 블록   | 엣지   | 카운트 변화 | 크래시 수
 ----------------+--------+--------+----------+------------------
    (초기 파일)  | 624    | 717    | 1.00     | -
               |        |        |          |
    블라인드 퍼징 | 1,101  | 1,409  | 1.60     | 0
    블록 커버리지 | 1,255  | 1,649  | 1.48     | 0
    엣지 커버리지 | 1,259  | 1,734  | 1.72     | 0
       AFL 모델 | 1,452  | 2,040  | 3.16     | 1
```

앞서 언급했듯이, 유전적 퍼징에 대한 일부 이전 연구는 단일 테스트 케이스를 유지하고 커버리지를 최대화하도록 진화시키는 것에 의존했습니다. 적어도 위에서 설명한 테스트에서, 이 `욕심쟁이` 접근법은 블라인드 퍼징 전략에 비해 실질적인 이점을 제공하지 않는 것으로 보입니다.

### 4. 코퍼스 선별하기
위에서 설명한 점진적 상태 탐색 접근법은 후반에 합성된 일부 테스트 케이스들이 그들의 조상 케이스들이 제공하는 커버리지의 상위집합인 엣지 커버리지를 가질 수 있음을 의미합니다.

퍼징 효율성을 최적화하기 위해, AFL은 주기적으로 빠른 알고리즘을 사용하여 큐를 재평가합니다. 이 알고리즘은 지금까지 본 모든 튜플을 여전히 커버하면서도 퍼저에게 특히 유리한 특성을 가진 **더 작은 테스트 케이스 부분집합** 을 선택합니다.

이 알고리즘은 모든 큐 항목에 실행 지연시간과 파일 크기에 비례하는 점수를 할당한 다음, 각 튜플에 대해 가장 낮은 점수를 받은 후보들을 선택하는 방식으로 작동합니다.

그런 다음 튜플들은 간단한 워크플로우를 사용하여 순차적으로 처리됩니다:

1. 아직 임시 작업 세트(temporary working set)에 없는 다음 튜플 찾기
2. 이 튜플에 대한 **winning queue** 항목 찾기
3. 해당 항목의 트레이스에 있는 모든 튜플을 작업 세트에 등록
4. 세트에 누락된 튜플이 있으면 1번으로 돌아가기

생성된 `선호` 항목들의 코퍼스는 일반적으로 시작 데이터 세트보다 5-10배 작습니다. 선호되지 않는 항목들은 버려지지 않지만, 큐에서 만날 때 다양한 확률로 건너뛰어집니다:

- 큐에 아직 퍼징되지 않은 새로운 선호 항목들이 있는 경우, 선호되지 않는 항목들의 99%가 건너뛰어져서 선호 항목들에 도달하게 됩니다.
- 새로운 선호 항목이 없는 경우:
    - 현재 선호되지 않는 항목이 이전에 퍼징된 적이 있다면, 95%의 확률로 건너뛰어집니다.
    - 아직 어떤 퍼징 라운드도 거치지 않았다면, 건너뛸 확률은 75%로 떨어집니다.


경험적 테스트를 바탕으로, 이는 큐 순환 속도와 테스트 케이스 다양성 사이의 합리적인 균형을 제공합니다.

조금 더 정교하지만 훨씬 느린 선별 작업은 afl-cmin으로 입력 또는 출력 코퍼스에 대해 수행할 수 있습니다. 이 도구는 중복 항목들을 영구적으로 제거하고 afl-fuzz나 외부 도구와 함께 사용하기에 적합한 더 작은 코퍼스를 생성합니다.

### 5. 입력 파일 트리밍하기
파일 크기는 퍼징 성능에 극적인 영향을 미칩니다. 큰 파일은 대상 바이너리를 느리게 만들 뿐만 아니라, **중요한 format control 구조들** 이 아닌 덜 중요한 데이터 블록에 변이가 적용될 가능성을 높이기 때문입니다. 이에 대한 자세한 내용은 `perf_tips.txt`에서 논의됩니다.

사용자가 낮은 품질의 시작 코퍼스를 제공할 가능성을 차치하고라도, 일부 유형의 변이는 생성된 파일의 크기를 반복적으로 증가시키는 효과를 가질 수 있으므로, 이러한 경향에 대응하는 것이 중요합니다.

다행히, **계측 피드백(instrumentation feedback)** 은 파일에 가해진 변경이 실행 경로에 영향을 주지 않도록 보장하면서 입력 파일을 자동으로 축소(**trim-down**)할 수 있는 간단한 방법을 제공합니다.

afl-fuzz의 내장 트리머는 **가변 길이와 스텝오버** 를 가진 데이터 블록을 순차적으로 제거하려고 시도합니다. 트레이스 맵의 체크섬에 영향을 주지 않는 모든 삭제는 디스크에 커밋됩니다. 트리머는 특별히 철저하게 설계되지 않았습니다. 대신, 정밀성과 이 과정에 소비되는 execve() 호출 수 사이의 균형을 맞추려고 시도하며, 이에 맞춰 블록 크기와 스텝오버를 선택합니다. 파일당 평균 축소율은 약 5-20%입니다.

독립형 afl-tmin 도구는 더 철저하고 반복적인 알고리즘을 사용하며, 트리밍된 파일에 대해 알파벳 정규화도 시도합니다. afl-tmin의 동작은 다음과 같습니다.

먼저, 이 도구는 자동으로 동작 모드를 선택합니다. 초기 입력이 대상 바이너리를 크래시시키면, afl-tmin은 비계측 모드로 실행되어 더 간단한 파일을 생성하지만 여전히 대상을 크래시시키는 모든 조정을 유지합니다. 대상이 크래시하지 않으면, 이 도구는 계측 모드를 사용하고 정확히 동일한 실행 경로를 생성하는 조정만 유지합니다.

실제 최소화 알고리즘은 다음과 같습니다:
1. 큰 스텝오버를 가진 큰 데이터 블록을 0으로 만들기 시도. 경험적으로, 이는 나중에 세밀한 노력을 미리 차단함으로써 실행 횟수를 줄이는 것으로 나타났습니다.
2. 블록 크기와 스텝오버를 감소시키면서 이진 탐색 스타일로 블록 삭제 패스 수행.
3. 고유 문자를 세고 각각을 0 값으로 일괄 교체하여 알파벳 정규화 수행.
4. 마지막 수단으로, 0이 아닌 바이트에 대해 바이트별 정규화 수행.

0x00 바이트로 0화하는 대신, afl-tmin은 **ASCII 숫자 '0'** 을 사용합니다. 이러한 수정이 텍스트 파싱을 방해할 가능성이 훨씬 낮기 때문에 텍스트 파일의 성공적인 최소화를 가져올 가능성이 더 높기 때문입니다.

여기서 사용된 알고리즘은 학술 연구에서 제안된 일부 다른 테스트 케이스 최소화 접근법보다는 덜 복잡하지만, 훨씬 적은 실행 횟수를 필요로 하며 대부분의 실제 애플리케이션에서 비교 가능한 결과를 생성하는 경향이 있습니다.